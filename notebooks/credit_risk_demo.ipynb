{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Prediction Model - Demonstration\n",
    "\n",
    "This notebook demonstrates the usage of the comprehensive credit risk prediction model framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from credit_risk_model import DataPreprocessor, FeatureEngineer, ModelTrainer, ModelEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Creation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data preprocessor\n",
    "preprocessor = DataPreprocessor(random_state=42)\n",
    "\n",
    "# Create sample dataset\n",
    "X, y = preprocessor.create_sample_dataset(n_samples=1000, n_features=8)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Features: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X_train, X_test, y_train, y_test = preprocessor.preprocess_pipeline(X, y, test_size=0.3)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model trainer\n",
    "trainer = ModelTrainer(random_state=42)\n",
    "\n",
    "# Train multiple models\n",
    "models = trainer.train_all_models(\n",
    "    X_train, y_train,\n",
    "    models_to_train=['logistic_regression', 'random_forest', 'xgboost'],\n",
    "    use_grid_search=False,\n",
    "    handle_imbalance='smote'\n",
    ")\n",
    "\n",
    "# Display training summary\n",
    "summary = trainer.get_model_summary()\n",
    "print(\"Training Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# Compare models\n",
    "comparison = evaluator.compare_models(models, X_test, y_test)\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model comparison\n",
    "plt.figure(figsize=(15, 10))\n",
    "evaluator.plot_model_comparison(models, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model_name = comparison.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# Generate detailed report\n",
    "report = evaluator.generate_evaluation_report(best_model_name)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance if available\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(range(len(importance_df)), importance_df['importance'])\n",
    "    plt.yticks(range(len(importance_df)), importance_df['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 5 Features:\")\n",
    "    print(importance_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Create predictions dataframe\n",
    "predictions_df = pd.DataFrame({\n",
    "    'actual': y_test,\n",
    "    'predicted': y_pred,\n",
    "    'probability': y_prob\n",
    "})\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(predictions_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Business Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate business metrics\n",
    "business_metrics = evaluator.calculate_business_metrics(y_test, y_pred, y_prob)\n",
    "\n",
    "print(\"Business Impact Analysis:\")\n",
    "print(f\"Net Profit: ${business_metrics['net_profit']:,.2f}\")\n",
    "print(f\"Total Revenue: ${business_metrics['total_revenue']:,.2f}\")\n",
    "print(f\"Total Losses: ${business_metrics['total_losses']:,.2f}\")\n",
    "print(f\"Approval Rate: {business_metrics['approval_rate']:.2%}\")\n",
    "print(f\"Profit Margin: {business_metrics['profit_margin']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates the complete workflow of the credit risk prediction model:\n",
    "\n",
    "1. **Data Creation**: Generate realistic credit risk datasets\n",
    "2. **Preprocessing**: Handle missing values, outliers, and feature scaling\n",
    "3. **Model Training**: Train multiple ML models with class imbalance handling\n",
    "4. **Evaluation**: Comprehensive performance evaluation with business metrics\n",
    "5. **Visualization**: Generate plots for model comparison and analysis\n",
    "6. **Interpretation**: Feature importance and business impact analysis\n",
    "\n",
    "The framework provides a robust foundation for credit risk modeling that can be extended with additional features and models as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}